---
title: "Demos"
permalink: /demos/
author_profile: false
---

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-131324268-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-131324268-1');
</script>

# Welcome to My Playground! ðŸŽ‰

This is where I showcase interactive demos of my latest and greatest projects. Dive in, explore, and see what I've been working on!

## [TALI Dataset Explorer](/demos/tali) ðŸš€

Hosted on Gradio, the TALI Dataset Explorer is a project I'm particularly excited about. 

### What's TALI?

TALI is my response, along with my collaborators, to the growing demand for multimodal understanding in deep learning. While unimodal datasets like ImageNet, SQuAD, and CoLA have been instrumental, and duomodal image-to-text pairings have pushed the boundaries, we believe it's time for a broader perspective.

TALI is a large-scale, tetramodal dataset that aligns text, video, images, and audio. It's a playground for innovative self-supervised learning tasks and multimodal research. With TALI, we're exploring how different modalities and data/model scaling affect downstream performance.

I'm excited about the diverse research ideas TALI will inspire, and I believe it will enhance our understanding of model capabilities and robustness in deep learning. So go ahead, [give TALI a try](/demos/tali)!

Stay tuned for more demos coming soon! ðŸŽˆ
